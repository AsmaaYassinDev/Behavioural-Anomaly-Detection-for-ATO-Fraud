{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsmaaYassinDev/Behavioural-Anomaly-Detection-for-ATO-Fraud/blob/main/Autoencoder_Experiment_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NYhSzAkuHnZ",
        "outputId": "fe37763b-0674-46fb-f499-440e38c3beab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"--- Autoencoder Execution Started (Unsupervised) ---\")\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "file_path = '/content/drive/My Drive/Colab_Data/PS_20174392719_1491204439457_log.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"Data Loaded: {len(df)} rows\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Build Behavioral Profiles (Engineered Features) ---\n",
        "print(\"\\n--- Building Behavioral Profiles ---\")\n",
        "df_received = df[df['type'].isin(['TRANSFER', 'CASH_IN'])]\n",
        "total_received = df_received.groupby('nameDest')['amount'].sum().to_dict()\n",
        "unique_senders = df_received.groupby('nameDest')['nameOrig'].nunique().to_dict()\n",
        "df_cashed_out = df[df['type'] == 'CASH_OUT']\n",
        "total_cashed_out = df_cashed_out.groupby('nameOrig')['amount'].sum().to_dict()\n",
        "\n",
        "all_user_ids = set(total_received.keys()) | set(total_cashed_out.keys()) | set(unique_senders.keys())\n",
        "profiles_list = []\n",
        "for user_id in all_user_ids:\n",
        "    received = total_received.get(user_id, 0)\n",
        "    cashed_out = total_cashed_out.get(user_id, 0)\n",
        "    senders = unique_senders.get(user_id, 0)\n",
        "    ratio = cashed_out / (received + 1e-6)\n",
        "    ratio = min(ratio, 1.0)\n",
        "    profiles_list.append({\n",
        "        'user_id': user_id,\n",
        "        'dest_cash_out_ratio': ratio,\n",
        "        'dest_unique_senders': senders\n",
        "    })\n",
        "final_profiles = pd.DataFrame(profiles_list)\n",
        "\n",
        "# --- 3. Create Smart Sample ---\n",
        "print(\"\\n--- Creating Smart Sample ---\")\n",
        "df_fraud = df[df['isFraud'] == 1]\n",
        "fraud_dest_ids = df_fraud['nameDest'].unique()\n",
        "fraud_orig_ids = df_fraud['nameOrig'].unique()\n",
        "all_fraud_user_ids = np.union1d(fraud_dest_ids, fraud_orig_ids)\n",
        "\n",
        "df_fraud_lifecycle = df[\n",
        "    df['nameOrig'].isin(all_fraud_user_ids) |\n",
        "    df['nameDest'].isin(all_fraud_user_ids)\n",
        "]\n",
        "df_normal = df[df['isFraud'] == 0]\n",
        "df_normal_sample = df_normal.sample(n=min(500000, len(df_normal)), random_state=42)\n",
        "\n",
        "df_smart_sample = pd.concat([df_fraud_lifecycle, df_normal_sample]).drop_duplicates()\n",
        "print(f\"Smart Sample Created: {len(df_smart_sample)} rows\")\n",
        "\n",
        "# --- 4. Merge Features ---\n",
        "print(\"\\n--- Merging Features with Transactions ---\")\n",
        "df_model_data = pd.merge(df_smart_sample, final_profiles, left_on='nameDest', right_on='user_id', how='left')\n",
        "df_model_data = pd.merge(df_model_data, final_profiles, left_on='nameOrig', right_on='user_id', how='left', suffixes=('_dest', '_orig'))\n",
        "\n",
        "for col in ['dest_cash_out_ratio_dest', 'dest_unique_senders_dest', 'dest_cash_out_ratio_orig', 'dest_unique_senders_orig']:\n",
        "    df_model_data[col] = df_model_data[col].fillna(0)\n",
        "\n",
        "# Hybrid Engineering\n",
        "df_model_data['balance_diff_orig'] = df_model_data['oldbalanceOrg'] - df_model_data['newbalanceOrig']\n",
        "df_model_data['balance_diff_dest'] = df_model_data['newbalanceDest'] - df_model_data['oldbalanceDest']\n",
        "df_model_data['type_encoded'] = df_model_data['type'].astype('category').cat.codes\n",
        "\n",
        "# Select Features (Hybrid Set)\n",
        "selected_features = [\n",
        "    'amount',\n",
        "    'type_encoded',\n",
        "    'dest_cash_out_ratio_dest',\n",
        "    'dest_unique_senders_dest',\n",
        "    'dest_cash_out_ratio_orig',\n",
        "    'dest_unique_senders_orig',\n",
        "    'balance_diff_orig',\n",
        "    'balance_diff_dest'\n",
        "]\n",
        "\n",
        "df_model_data = df_model_data.dropna(subset=['isFraud'])\n",
        "X = df_model_data[selected_features]\n",
        "y = df_model_data['isFraud']\n",
        "\n",
        "# Scale Features (Critical for Autoencoders)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split Data (Standard Stratified Split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# --- 5. Train Autoencoder ---\n",
        "print(\"\\n--- Training Autoencoder ---\")\n",
        "\n",
        "# IMPORTANT: Train ONLY on Normal transactions (y=0)\n",
        "# The goal is for the model to learn \"Normalcy\" and fail on \"Fraud\"\n",
        "X_train_normal = X_train[y_train == 0]\n",
        "\n",
        "# Model Architecture\n",
        "input_dim = X_train.shape[1]\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "\n",
        "# Encoder (Compressing)\n",
        "encoder = Dense(16, activation=\"tanh\")(input_layer)\n",
        "encoder = Dense(8, activation=\"relu\")(encoder)\n",
        "\n",
        "# Decoder (Reconstructing)\n",
        "decoder = Dense(16, activation='tanh')(encoder)\n",
        "decoder = Dense(input_dim, activation='linear')(decoder) # Output layer matches input dimension\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = autoencoder.fit(\n",
        "    X_train_normal, X_train_normal, # Input and Target are the same\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    validation_data=(X_test, X_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- 6. Detect Anomalies (Reconstruction Error) ---\n",
        "print(\"\\n--- Predicting Anomalies ---\")\n",
        "\n",
        "# 1. Predict the output for the test set\n",
        "predictions = autoencoder.predict(X_test)\n",
        "\n",
        "# 2. Calculate MSE (Reconstruction Error) for each transaction\n",
        "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
        "\n",
        "# 3. Set a Threshold\n",
        "# We assume the top X% of errors are fraud (where X is the actual fraud rate in training)\n",
        "threshold = np.quantile(mse, 1 - y_train.mean())\n",
        "\n",
        "print(f\"Reconstruction Error Threshold: {threshold:.4f}\")\n",
        "\n",
        "# 4. Classify: If Error > Threshold, it's Fraud (1)\n",
        "y_pred = [1 if e > threshold else 0 for e in mse]\n",
        "\n",
        "# --- 7. Evaluate Results ---\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"      RESULTS: Autoencoder (Unsupervised)\")\n",
        "print(\"=======================================================\")\n",
        "print(f\"Precision: {precision:.2%}\")\n",
        "print(f\"Recall:    {recall:.2%}\")\n",
        "print(f\"F1-Score:  {f1:.2%}\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"=======================================================\")\n",
        "print(\"\\n--- Execution Complete ---\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Autoencoder Execution Started (Unsupervised) ---\n",
            "Data Loaded: 6362620 rows\n",
            "\n",
            "--- Building Behavioral Profiles ---\n",
            "\n",
            "--- Creating Smart Sample ---\n",
            "Smart Sample Created: 561154 rows\n",
            "\n",
            "--- Merging Features with Transactions ---\n",
            "\n",
            "--- Training Autoencoder ---\n",
            "Epoch 1/10\n",
            "\u001b[1m12096/12096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.3045 - val_loss: 0.4598\n",
            "Epoch 2/10\n",
            "\u001b[1m12096/12096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.1680 - val_loss: 0.3838\n",
            "Epoch 3/10\n",
            "\u001b[1m12096/12096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3ms/step - loss: 0.1042 - val_loss: 0.3243\n",
            "Epoch 4/10\n",
            "\u001b[1m12096/12096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 0.1078 - val_loss: 0.3132\n",
            "Epoch 5/10\n",
            "\u001b[1m12096/12096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 0.0841 - val_loss: 0.2978\n",
            "Epoch 6/10\n",
            "\u001b[1m12096/12096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 0.0675 - val_loss: 0.2899\n",
            "Epoch 7/10\n",
            "\u001b[1m12096/12096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 0.0432 - val_loss: 0.2999\n",
            "Epoch 8/10\n",
            "\u001b[1m12096/12096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 0.0476 - val_loss: 0.3221\n",
            "Epoch 9/10\n",
            "\u001b[1m12096/12096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 0.0402 - val_loss: 0.2926\n",
            "Epoch 10/10\n",
            "\u001b[1m12096/12096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - loss: 0.0311 - val_loss: 0.3035\n",
            "\n",
            "--- Predicting Anomalies ---\n",
            "\u001b[1m5261/5261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
            "Reconstruction Error Threshold: 0.0972\n",
            "\n",
            "=======================================================\n",
            "      RESULTS: Autoencoder (Unsupervised)\n",
            "=======================================================\n",
            "Precision: 44.20%\n",
            "Recall:    44.20%\n",
            "F1-Score:  44.20%\n",
            "-------------------------------------------------------\n",
            "Confusion Matrix:\n",
            "[[164508   1375]\n",
            " [  1375   1089]]\n",
            "=======================================================\n",
            "\n",
            "--- Execution Complete ---\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-HwNhY6uDKt",
        "outputId": "4804f459-27d1-4d62-d66d-16e34c68a3b0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}