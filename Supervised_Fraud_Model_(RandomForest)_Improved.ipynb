{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsmaaYassinDev/Behavioural-Anomaly-Detection-for-ATO-Fraud/blob/main/Supervised_Fraud_Model_(RandomForest)_Improved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agM4MsRZq92G",
        "outputId": "9c34189f-f958-494e-e963-d05f3c60d946"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"--- Improved Random Forest Execution Started ---\")\n",
        "\n",
        "# --- Load Smart Sample ---\n",
        "file_path = '/content/drive/My Drive/Colab_Data/PS_20174392719_1491204439457_log.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "print(f\"Data Loaded: {len(df)} rows\")\n",
        "\n",
        "# --- Build behavioral features ---\n",
        "print(\"\\n--- Building Behavioral Profiles ---\")\n",
        "df_received = df[df['type'].isin(['TRANSFER', 'CASH_IN'])]\n",
        "total_received = df_received.groupby('nameDest')['amount'].sum().to_dict()\n",
        "unique_senders = df_received.groupby('nameDest')['nameOrig'].nunique().to_dict()\n",
        "df_cashed_out = df[df['type'] == 'CASH_OUT']\n",
        "total_cashed_out = df_cashed_out.groupby('nameOrig')['amount'].sum().to_dict()\n",
        "\n",
        "all_user_ids = set(total_received.keys()) | set(total_cashed_out.keys()) | set(unique_senders.keys())\n",
        "profiles_list = []\n",
        "for user_id in all_user_ids:\n",
        "    received = total_received.get(user_id, 0)\n",
        "    cashed_out = total_cashed_out.get(user_id, 0)\n",
        "    senders = unique_senders.get(user_id, 0)\n",
        "    ratio = cashed_out / (received + 1e-6)\n",
        "    ratio = min(ratio, 1.0)\n",
        "    profiles_list.append({\n",
        "        'user_id': user_id,\n",
        "        'dest_cash_out_ratio': ratio,\n",
        "        'dest_unique_senders': senders\n",
        "    })\n",
        "final_profiles = pd.DataFrame(profiles_list)\n",
        "\n",
        "# --- Create Smart Sample ---\n",
        "print(\"\\n--- Creating Smart Sample ---\")\n",
        "df_fraud = df[df['isFraud'] == 1]\n",
        "fraud_dest_ids = df_fraud['nameDest'].unique()\n",
        "fraud_orig_ids = df_fraud['nameOrig'].unique()\n",
        "all_fraud_user_ids = np.union1d(fraud_dest_ids, fraud_orig_ids)\n",
        "\n",
        "df_fraud_lifecycle = df[\n",
        "    df['nameOrig'].isin(all_fraud_user_ids) |\n",
        "    df['nameDest'].isin(all_fraud_user_ids)\n",
        "]\n",
        "df_normal = df[df['isFraud'] == 0]\n",
        "df_normal_sample = df_normal.sample(n=min(500000, len(df_normal)), random_state=42)\n",
        "\n",
        "df_smart_sample = pd.concat([df_fraud_lifecycle, df_normal_sample]).drop_duplicates()\n",
        "print(f\"Smart Sample Created: {len(df_smart_sample)} rows\")\n",
        "\n",
        "# --- Merge Features ---\n",
        "print(\"\\n--- Merging Features with Transactions ---\")\n",
        "df_model_data = pd.merge(df_smart_sample, final_profiles, left_on='nameDest', right_on='user_id', how='left')\n",
        "df_model_data = pd.merge(df_model_data, final_profiles, left_on='nameOrig', right_on='user_id', how='left', suffixes=('_dest', '_orig'))\n",
        "\n",
        "# Fill missing values\n",
        "for col in ['dest_cash_out_ratio_dest', 'dest_unique_senders_dest', 'dest_cash_out_ratio_orig', 'dest_unique_senders_orig']:\n",
        "    df_model_data[col] = df_model_data[col].fillna(0)\n",
        "\n",
        "# Feature engineering\n",
        "df_model_data['balance_diff_orig'] = df_model_data['oldbalanceOrg'] - df_model_data['newbalanceOrig']\n",
        "df_model_data['balance_diff_dest'] = df_model_data['newbalanceDest'] - df_model_data['oldbalanceDest']\n",
        "df_model_data['type_encoded'] = df_model_data['type'].astype('category').cat.codes\n",
        "\n",
        "# Time-based features\n",
        "df_model_data['hour'] = df_model_data['step'] % 24\n",
        "df_model_data['is_night'] = df_model_data['hour'].apply(lambda x: 1 if x < 6 or x > 22 else 0)\n",
        "df_model_data['is_working_hour'] = df_model_data['hour'].apply(lambda x: 1 if 8 <= x <= 17 else 0)\n",
        "df_model_data['is_weekend'] = df_model_data['step'].apply(lambda x: 1 if (x // 24) % 7 in [5, 6] else 0)\n",
        "\n",
        "# --- Prepare Final Dataset ---\n",
        "selected_features = [\n",
        "    'amount',\n",
        "    'type_encoded',\n",
        "    'balance_diff_orig',\n",
        "    'balance_diff_dest',\n",
        "     'dest_cash_out_ratio_dest',\n",
        "    'dest_unique_senders_dest',\n",
        "    'dest_cash_out_ratio_orig',\n",
        "    'dest_unique_senders_orig',\n",
        "    'hour',\n",
        "    'is_night',\n",
        "    'is_working_hour',\n",
        "    'is_weekend'\n",
        "]\n",
        "df_model_data = df_model_data.dropna(subset=['isFraud'])\n",
        "X = df_model_data[selected_features]\n",
        "y = df_model_data['isFraud']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n",
        "print(f\"Training size: {len(X_train)}, Test size: {len(X_test)}\")\n",
        "\n",
        "# --- Train Random Forest ---\n",
        "print(\"\\n--- Training Random Forest Classifier ---\")\n",
        "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict & Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- Random Forest Results After Feature Selection ---\")\n",
        "print(f\"Precision: {precision:.2%}\")\n",
        "print(f\"Recall: {recall:.2%}\")\n",
        "print(f\"F1-Score: {f1:.2%}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Feature Importance\n",
        "importance = pd.Series(model.feature_importances_, index=selected_features).sort_values(ascending=False)\n",
        "print(\"\\n--- Feature Importance ---\")\n",
        "print(importance)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Improved Random Forest Execution Started ---\n",
            "Data Loaded: 6362620 rows\n",
            "\n",
            "--- Building Behavioral Profiles ---\n",
            "\n",
            "--- Creating Smart Sample ---\n",
            "Smart Sample Created: 561154 rows\n",
            "\n",
            "--- Merging Features with Transactions ---\n",
            "Training size: 392807, Test size: 168347\n",
            "\n",
            "--- Training Random Forest Classifier ---\n",
            "\n",
            "--- Random Forest Results After Feature Selection ---\n",
            "Precision: 92.30%\n",
            "Recall: 81.21%\n",
            "F1-Score: 86.40%\n",
            "Confusion Matrix:\n",
            "[[165716    167]\n",
            " [   463   2001]]\n",
            "\n",
            "--- Feature Importance ---\n",
            "balance_diff_orig    0.502474\n",
            "balance_diff_dest    0.138697\n",
            "type_encoded         0.130670\n",
            "amount               0.129783\n",
            "hour                 0.074846\n",
            "is_night             0.018416\n",
            "is_working_hour      0.003359\n",
            "is_weekend           0.001755\n",
            "dtype: float64\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN_IwceT2_AK",
        "outputId": "05254f62-f1e3-41b4-af1f-d80fde47d3fe"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}