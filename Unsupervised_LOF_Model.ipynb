{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6YtYaRpSKBLWz1FbE0PQa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsmaaYassinDev/Behavioural-Anomaly-Detection-for-ATO-Fraud/blob/main/Unsupervised_LOF_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7gfyRKzDKYX",
        "outputId": "78350a9d-baa1-449d-b21f-dcdff09a149d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jjau-qJ7CVR",
        "outputId": "ceb8e48b-314b-4b52-e059-cca2570e66f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Execution Started (Improved LOF) ---\n",
            "Objective: Use LOF with full behavioral + engineered features.\n",
            "Successfully loaded the full file (6362620 rows).\n",
            "\n",
            "--- Step 1: Creating the 'Smart Sample' ---\n",
            "The final 'Smart Sample' was created with 561154 rows.\n",
            "\n",
            "--- Step 2: Building Behavioral Profiles ---\n",
            "Behavioral profiles created successfully.\n",
            "\n",
            "--- Step 3: Merging Features with Transactions ---\n",
            "\n",
            "--- Step 4: Training Local Outlier Factor (LOF) Model ---\n",
            "Fraud (Contamination) rate in the Smart Sample: 1.46%\n",
            "Model training complete.\n",
            "\n",
            "--- Step 5: Evaluating the LOF Model ---\n",
            "Precision: 4.94%\n",
            "Recall: 4.94%\n",
            "F1-Score (Final score for LOF): 4.94%\n",
            "\n",
            "Confusion Matrix:\n",
            "[[545134   7807]\n",
            " [  7807    406]]\n",
            "\n",
            "--- LOF Code Execution Complete ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "print(\"--- Execution Started (Improved LOF) ---\")\n",
        "print(\"Objective: Use LOF with full behavioral + engineered features.\")\n",
        "\n",
        "# --- Load Data ---\n",
        "file_path = '/content/drive/My Drive/Colab_Data/PS_20174392719_1491204439457_log.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"Successfully loaded the full file ({len(df)} rows).\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during data loading: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- Step 1: Create the 'Smart Sample' ---\n",
        "print(\"\\n--- Step 1: Creating the 'Smart Sample' ---\")\n",
        "df_fraud = df[df['isFraud'] == 1]\n",
        "fraud_dest_ids = df_fraud['nameDest'].unique()\n",
        "fraud_orig_ids = df_fraud['nameOrig'].unique()\n",
        "all_fraud_user_ids = np.union1d(fraud_dest_ids, fraud_orig_ids)\n",
        "df_fraud_lifecycle = df[\n",
        "    df['nameOrig'].isin(all_fraud_user_ids) |\n",
        "    df['nameDest'].isin(all_fraud_user_ids)\n",
        "]\n",
        "df_normal = df[df['isFraud'] == 0]\n",
        "sample_size = min(500000, len(df_normal))\n",
        "df_normal_sample = df_normal.sample(n=sample_size, random_state=42)\n",
        "df_smart_sample = pd.concat([df_fraud_lifecycle, df_normal_sample]).drop_duplicates(keep='first')\n",
        "print(f\"The final 'Smart Sample' was created with {len(df_smart_sample)} rows.\")\n",
        "\n",
        "# --- Step 2: Build Behavioral Profiles (Strong Features) ---\n",
        "print(\"\\n--- Step 2: Building Behavioral Profiles ---\")\n",
        "\n",
        "# (a) Calculate basic statistics\n",
        "df_received = df_smart_sample[df_smart_sample['type'].isin(['TRANSFER', 'CASH_IN'])]\n",
        "total_received = df_received.groupby('nameDest')['amount'].sum().to_dict()\n",
        "unique_senders = df_received.groupby('nameDest')['nameOrig'].nunique().to_dict()\n",
        "df_cashed_out = df_smart_sample[df_smart_sample['type'] == 'CASH_OUT']\n",
        "total_cashed_out = df_cashed_out.groupby('nameOrig')['amount'].sum().to_dict()\n",
        "\n",
        "all_user_ids = set(total_received.keys()) | set(total_cashed_out.keys()) | set(unique_senders.keys())\n",
        "profiles_list = []\n",
        "for user_id in all_user_ids:\n",
        "    received = total_received.get(user_id, 0)\n",
        "    cashed_out = total_cashed_out.get(user_id, 0)\n",
        "    senders = unique_senders.get(user_id, 0)\n",
        "    ratio = (cashed_out / (received + 1e-6))\n",
        "    ratio = min(ratio, 1.0)\n",
        "    profiles_list.append({\n",
        "        'user_id': user_id,\n",
        "        'dest_cash_out_ratio': ratio,\n",
        "        'dest_unique_senders': senders\n",
        "    })\n",
        "final_profiles = pd.DataFrame(profiles_list)\n",
        "print(\"Behavioral profiles created successfully.\")\n",
        "\n",
        "# --- Step 3: Merge Features with Transactions ---\n",
        "print(\"\\n--- Step 3: Merging Features with Transactions ---\")\n",
        "df_model_data = pd.merge(df_smart_sample, final_profiles, left_on='nameDest', right_on='user_id', how='left')\n",
        "df_model_data = pd.merge(df_model_data, final_profiles, left_on='nameOrig', right_on='user_id', how='left', suffixes=('_dest', '_orig'))\n",
        "\n",
        "df_model_data['dest_cash_out_ratio_dest'] = df_model_data['dest_cash_out_ratio_dest'].fillna(0)\n",
        "df_model_data['dest_unique_senders_dest'] = df_model_data['dest_unique_senders_dest'].fillna(0)\n",
        "df_model_data['dest_cash_out_ratio_orig'] = df_model_data['dest_cash_out_ratio_orig'].fillna(0)\n",
        "df_model_data['dest_unique_senders_orig'] = df_model_data['dest_unique_senders_orig'].fillna(0)\n",
        "\n",
        "# --- Step 4: Train Unsupervised LOF Model ---\n",
        "print(\"\\n--- Step 4: Training Local Outlier Factor (LOF) Model ---\")\n",
        "\n",
        "features = [\n",
        "    'amount',\n",
        "    'dest_cash_out_ratio_dest',\n",
        "    'dest_unique_senders_dest',\n",
        "    'dest_cash_out_ratio_orig',\n",
        "    'dest_unique_senders_orig'\n",
        "]\n",
        "df_model_data['type_encoded'] = df_model_data['type'].astype('category').cat.codes\n",
        "features.append('type_encoded')\n",
        "\n",
        "X = df_model_data[features]\n",
        "y_true = df_model_data['isFraud'] # The \"Correct Answer\" (for comparison only)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "contamination = y_true.mean()\n",
        "print(f\"Fraud (Contamination) rate in the Smart Sample: {contamination:.2%}\")\n",
        "\n",
        "# --- (This is the change) ---\n",
        "# n_neighbors=20 is a common default setting\n",
        "model = LocalOutlierFactor(n_neighbors=20, contamination=contamination)\n",
        "\n",
        "# LOF uses .fit_predict() to give us -1 (anomalous) or 1 (normal)\n",
        "predictions = model.fit_predict(X_scaled)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# --- Step 5: Evaluation (Comparison) ---\n",
        "print(\"\\n--- Step 5: Evaluating the LOF Model ---\")\n",
        "\n",
        "# Convert the model's \"guess\" (-1) to (1) to match 'isFraud'\n",
        "y_pred = [1 if p == -1 else 0 for p in predictions]\n",
        "\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2%}\")\n",
        "print(f\"Recall: {recall:.2%}\")\n",
        "print(f\"F1-Score (Final score for LOF): {f1:.2%}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n--- LOF Code Execution Complete ---\")"
      ]
    }
  ]
}